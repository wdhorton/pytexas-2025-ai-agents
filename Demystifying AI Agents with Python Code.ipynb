{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72bc8a3-a78c-4be9-ab00-0e197b9dcdd9",
   "metadata": {},
   "source": [
    "# Demystifying AI Agents with Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4cb1aa-537a-4941-abe7-3d661391991c",
   "metadata": {},
   "source": [
    "Agent = LLM + memory + planning + tools + while loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afcf8ce-5689-4e3b-897d-4c3ed8bfc242",
   "metadata": {},
   "source": [
    "## 1. LLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "394bb894-2144-4a24-8a35-bcdb1e9b36e3",
   "metadata": {},
   "source": [
    "![ChatGPT.png](./ChatGPT.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d64e9-fc61-49fb-88a4-7298b20c2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0f2a8-ab8c-4587-94a3-a9a1b2e4a431",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "If you want to run this notebook with Google Gemini or Anthropic, the most straightforward approach would be to use the OpenAI-compatible endpoints that they provide. I have tested it with both, just uncomment the relevant code below.\n",
    "\n",
    "Documentation: \n",
    "- https://ai.google.dev/gemini-api/docs/openai\n",
    "- https://docs.anthropic.com/en/api/openai-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ea383-7d93-400a-87a8-b37acb33cd74",
   "metadata": {},
   "source": [
    "**Google**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f8479-41c7-447e-8e5d-400c2682011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# client = OpenAI(\n",
    "#     api_key=os.environ[\"GEMINI_API_KEY\"],\n",
    "#     base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "# )\n",
    "\n",
    "# MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262cba8-2de4-4d35-b6ae-aea619bd4ab3",
   "metadata": {},
   "source": [
    "**Anthropic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282afa5-57a2-4252-ae55-e13db5021eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# client = OpenAI(\n",
    "#     api_key=os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "#     base_url=\"https://api.anthropic.com/v1/\"\n",
    "# )\n",
    "\n",
    "# MODEL = \"claude-3-7-sonnet-20250219\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20869b2a-9335-4bbe-816c-846d4ff1eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about the Python programming language in a few sentences.\"}\n",
    "    ]\n",
    ")\n",
    "print(response.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f8113-6544-4ccf-9f60-824f801a3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_text = response.choices[0].message.content\n",
    "print(llm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf136fc4-fedb-479f-92a4-4a08fffbe711",
   "metadata": {},
   "source": [
    "### System or \"developer\" prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438501b5-1e92-4dac-8428-89509e3d6709",
   "metadata": {},
   "source": [
    "We can use the system message to give the model instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9e33e-9105-41d0-ace3-5be26d4e223b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Talk like a pirate\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about the Python programming language in a few sentences.\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486b580-c5e4-420a-976e-1fdb1b841f6f",
   "metadata": {},
   "source": [
    "System instructions take precedence over user instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26b9d8-a3f7-4737-84ff-f60f52fcf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Talk like a pirate\"},\n",
    "        {\"role\": \"user\", \"content\": \"Don't talk like a pirate. Tell me about the Python programming language in a few sentences.\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39244bee-494c-46e9-829e-962994ffc611",
   "metadata": {},
   "source": [
    "## 2. Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ca150-cc0c-4315-b23d-d481f50a0d36",
   "metadata": {},
   "source": [
    "The main LLM API (Chat Completions) is stateless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723df4ef-2eff-4f71-8e7c-a910d63f55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(message):\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b3b7a-a6f5-4b70-b19a-d1b6489a95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_llm(\"My name is William\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938767f-144b-4563-8d6b-9c34d1d51593",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_llm(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2348a29-a32e-4f4f-8bdf-74457f94cc40",
   "metadata": {},
   "source": [
    "The way to track state is by appending to the `messages` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df635f-522f-46af-9b5e-1ab4aab81ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me about the Python programming language in a few sentences.\"},\n",
    "        {\"role\": \"assistant\", \"content\": llm_text},\n",
    "        {\"role\": \"user\", \"content\": \"Can you elaborate on its use cases?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ac12a-dd34-4124-a37a-134c405670ba",
   "metadata": {},
   "source": [
    "You could represent this with a stateful class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd10362-e824-47bc-b523-be26869fb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def chat(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=self.messages,\n",
    "        )\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03364a03-0c84-4431-bb47-1a2c2b88ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ChatBot()\n",
    "bot.chat(\"My name is William\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d56801-e6e2-42bd-b5d1-1eb5e12bbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.chat(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b34216-140e-4216-88cd-3179c2ebdcc8",
   "metadata": {},
   "source": [
    "## 3. Planning + Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d0474-5b16-4325-a4e8-32e9e685ec15",
   "metadata": {},
   "source": [
    "Lets say you wanted your LLM to call a Python function that you've written.\n",
    "\n",
    "Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb53a0-2137-4030-8eef-4ca4a98a85e2",
   "metadata": {},
   "source": [
    "**Note**: Tool vs Function\n",
    "\n",
    "Earlier terminology was \"function\", but now people are shifting to \"tool\". Both are still used somewhat interchangeably.\n",
    "Strictly speaking, at least in OpenAI's terms, a \"function\" is one specific kind of \"tool\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0944531-ac8f-4309-83bd-9bf2f1249251",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who is currently leading the Masters?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c9c4c-c2a1-45c9-bcdc-d08f0231c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5629dc-06b9-41b4-9d23-a75d7915937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the web\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {\n",
    "      'X-API-KEY': os.environ[\"SERPER_API_KEY\"],\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {\n",
    "        \"q\": query\n",
    "    }\n",
    "    response = requests.post(\"https://google.serper.dev/search\", json=payload, headers=headers)    \n",
    "    return json.dumps(response.json()[\"organic\"], indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145fcd0-7264-4fe3-9c62-19485c7bc733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(search_web(\"masters 2025\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077e537-e316-49da-a861-4e4de1b24f2e",
   "metadata": {},
   "source": [
    "How do I get the LLM to use this function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844b128-ea4f-4429-9831-0f5edaa3baec",
   "metadata": {},
   "source": [
    "### Manual Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee81ff-14a3-42c8-ac0f-965489c4b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You have access to a search_web function that takes a query parameter. \n",
    "If you want to use it return just 'search_web(<query>)'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687185c-8cf7-4c83-8960-6d18950ea376",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"Who is currently leading the Masters?\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9cc1d1-4df8-498c-9553-24043e6b53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "iso_string = datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d14ad-7f26-4b94-8a24-2df7f90a151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"You have access to a search_web function that takes a query parameter. \n",
    "If you want to use it return just 'search_web(\"<query>\")'\n",
    "\n",
    "The current datetime is {datetime.now().isoformat()}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d169cba-743f-4e88-a8db-4d0a1305cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"Who is currently leading the Masters?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defe11f-fde4-4606-a218-8b7d3509c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_param(s: str) -> str | None:    \n",
    "    match = re.search(r'search_web\\(\"(.+?)\"\\)', s)\n",
    "    if match:\n",
    "        parameter = match.group(1)\n",
    "        return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc910ff-3701-4db6-8982-160d464513a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_param(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8241d-70bd-4fbc-ad20-9e893c44b615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(search_web('Masters Tournament 2025 current leader'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8f5a8-ca21-4356-9ef2-c22ffefd1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"Who is currently leading the Masters?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"\"\"search_web(\"current leader of the Masters Tournament 2025\")\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here are the results of search_web: {search_web('current leader of the Masters Tournament 2025')}\"},\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193a648-2953-4d5e-847c-563f8b507677",
   "metadata": {},
   "source": [
    "#### Overview: How do we get the LLM to interact with functions?\n",
    "\n",
    "1. Tell it the functions it can use and their parameters.\n",
    "2. Extract the function calls and parameters from response.\n",
    "3. Actually run the function with the parameters.\n",
    "4. Pass the function result to the LLM.\n",
    "5. Get the LLM's final response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76616560-f2bd-429f-8a3a-fc1a2bada040",
   "metadata": {},
   "source": [
    "### Provider APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97952d9-9c62-49ee-a512-e80bf1989b3b",
   "metadata": {},
   "source": [
    "Describing tools in this way is cumbersome and error-prone. So the providers have trained their models to recognize a specific syntax, and they provide parameters in their SDKs for specifying tools in structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83339e8a-cbf2-424c-93dc-99f47954abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEB_SEARCH_TOOL = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"search_web\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"query\"\n",
    "            ],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8cb3c-2d25-4b6b-8332-72fc678f8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = f\"\"\"The current datetime is {datetime.now().isoformat()}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd372c-9ebb-4008-b525-ee41066d1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"Who is currently leading the Masters?\"}\n",
    "    ],\n",
    "    tools=[WEB_SEARCH_TOOL]\n",
    ")\n",
    "print(response.choices[0].message.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405d30c-fa4b-4664-9cd5-018606b7328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "def extract_params(response) -> dict[str, Any]:    \n",
    "    return json.loads(response.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c8a88-59b3-401b-8309-8c0ee9955e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_params(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c580d-66ee-4bd5-87c1-95388597039c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_results = search_web(**extract_params(response))\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152ccb9-4529-419d-9c56-cbfc5d8b4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"Who is currently leading the Masters?\"},\n",
    "        # The LLM's previous response\n",
    "        response.choices[0].message,\n",
    "        {\"role\": \"tool\", \"tool_call_id\": response.choices[0].message.tool_calls[0].id, \"content\": search_results},\n",
    "    ],\n",
    "    tools=[WEB_SEARCH_TOOL]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d152a-d38f-45df-8a10-a722e52d272b",
   "metadata": {},
   "source": [
    "*Important note*: the LLM doesn't have to use the tools if they are not necessary. This is part of planning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7221a14-39df-49af-bd90-a38a13f02c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about Python programming\"},\n",
    "    ],\n",
    "    tools=[WEB_SEARCH_TOOL]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e302db4-a94f-4292-8680-aefb32369377",
   "metadata": {},
   "source": [
    "For convenience we can also automatically turn our functions into tool specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58d5da-cf58-4569-adfd-99573ba2a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.signature(search_web))\n",
    "print(inspect.signature(search_web).parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bade3a-9b61-4158-9fe7-4d36adabb7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def python_type_to_json_type(py_type):\n",
    "    mapping = {\n",
    "        str: \"string\",\n",
    "        int: \"integer\",\n",
    "        float: \"number\",\n",
    "        bool: \"boolean\"\n",
    "    }\n",
    "    # Default to \"string\" if the type is not in the mapping.\n",
    "    return mapping.get(py_type, \"string\")\n",
    "\n",
    "def function_to_tool_spec(fn):\n",
    "    sig = inspect.signature(fn)\n",
    "    properties = {}\n",
    "    required = []\n",
    "    \n",
    "    # Iterate over parameters of the function.\n",
    "    for param in sig.parameters.values():\n",
    "        \n",
    "        # Map the Python annotation to a JSON schema type.\n",
    "        param_schema = {\"type\": python_type_to_json_type(param.annotation)}\n",
    "        \n",
    "        # If the parameter has a default value, add it to the schema.\n",
    "        # Otherwise, mark it as required.\n",
    "        if param.default != inspect.Parameter.empty:\n",
    "            param_schema[\"default\"] = param.default\n",
    "        else:\n",
    "            required.append(param.name)\n",
    "        \n",
    "        properties[param.name] = param_schema\n",
    "\n",
    "    spec = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": fn.__name__,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": properties,\n",
    "                \"required\": required,\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9884a6-08e2-4ff9-9633-e8ba99d3524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_tool_spec(search_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f1fc9-77bf-47c9-bdb5-e28e0b4b8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_tool_spec(search_web) == WEB_SEARCH_TOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287c230-7f90-4c50-9c1e-25bb46586140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_with_tool_calling(message, functions):\n",
    "    # Map the function name to the actual function\n",
    "    fn_map = {fn.__name__: fn for fn in functions}\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=[function_to_tool_spec(fn) for fn in functions]\n",
    "    )\n",
    "\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    # while loop!\n",
    "    while tool_calls:\n",
    "        messages.append(response.choices[0].message)\n",
    "        for tool_call in tool_calls:\n",
    "            # Get the function from our mapping\n",
    "            fn = fn_map[tool_call.function.name]\n",
    "    \n",
    "            # Call the function with the specified args\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            print(f\"Calling {tool_call.function.name} with {args}\")\n",
    "            result = fn(**args)\n",
    "            messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": result})\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            tools=[function_to_tool_spec(fn) for fn in functions]\n",
    "        )\n",
    "\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254cb0d1-bdf0-498d-bc12-d8b907141407",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = call_llm_with_tool_calling(\"who is currently leading the masters?\", [search_web])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342653e-1cea-4123-ab75-e24f04576b42",
   "metadata": {},
   "source": [
    "## Our First Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d7e4fe-6359-4540-97ec-9364abf8943c",
   "metadata": {},
   "source": [
    "Combining LLMs, memory, and planning + tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85d217-c9c4-4dcc-9b93-d32439191915",
   "metadata": {},
   "source": [
    "We have to slightly modify the previous function to work well with our message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24fd000-3408-4db8-ac8b-fca7e452692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_with_tool_calling(message, functions, message_history=None):\n",
    "    fn_map = {fn.__name__: fn for fn in functions}\n",
    "\n",
    "    # We can pass in the previous messages. If there are none, we start from scratch.\n",
    "    if message_history is None:\n",
    "        message_history = []\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=message_history + messages,\n",
    "        tools=[function_to_tool_spec(fn) for fn in functions]\n",
    "    )\n",
    "\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    while tool_calls:\n",
    "        messages.append(response.choices[0].message)\n",
    "        for tool_call in tool_calls:\n",
    "            # Get the function from our mapping\n",
    "            fn = fn_map[tool_call.function.name]\n",
    "    \n",
    "            # Call the function with the specified args\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            result = fn(**args)\n",
    "            messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": result})\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=message_history + messages,\n",
    "            tools=[function_to_tool_spec(fn) for fn in functions]\n",
    "        )\n",
    "\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    return response.choices[0].message.content, messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df07d8a-6514-4b48-8582-77fc0fd87537",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, functions, system_prompt=SYSTEM_PROMPT):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "        self.functions = functions\n",
    "\n",
    "    def chat(self, message):\n",
    "        output, messages = call_llm_with_tool_calling(message, self.functions, message_history=self.messages)\n",
    "        self.messages += messages\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2b40e-2854-48e9-bb70-1739b0919322",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(functions=[search_web])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1563e2d-6a48-4fd2-a48b-3fc86f6283f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.chat(\"Hi! I am interested in AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8bedf-d5bf-4bff-870f-9e482fc46aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.chat(\"Can you find events in Austin that I might like?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7be4ae5-13d6-4959-88d5-241694338829",
   "metadata": {},
   "source": [
    "## Agent Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b58e42-db15-46fd-b790-daf456174a4f",
   "metadata": {},
   "source": [
    "That can be a lot of code to write on top of the OpenAI SDK. Many frameworks have popped up that abstract that away from you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b71054-e5cd-4525-a2aa-a07eaa6fb9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from crewai.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53425a58-d8b8-446d-9fac-7d25c2d8f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    role=\"searcher\",\n",
    "    goal=\"Get information for the user\",\n",
    "    backstory=\"\",\n",
    "    tools=[tool(search_web)]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c06751-21c7-46b9-905f-eee306d6260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(\n",
    "    description=\"{query}\",\n",
    "    expected_output=\"Answers for {query}\",\n",
    "    agent=agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d9cad-3dc6-4690-ab7b-249912d92d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f771854-09b1-47d6-8854-75db827c9edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = crew.kickoff(inputs={\"query\": \"Who is currently leading the Masters in 2025?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edcc91f-9f9f-4c32-ae25-66100e80e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282687a-ec7b-4d23-93a3-bc580434d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3faac0-f4de-4f8b-8201-a4d4aa7a8389",
   "metadata": {},
   "source": [
    "#### Multiple tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c48f7-8ab5-49c6-9405-e9a1ced16c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text\n",
    "import requests\n",
    "\n",
    "def fetch_url(url: str) -> str:\n",
    "    \"Get the content at a specific URL\"\n",
    "    response = requests.get(url)\n",
    "    h = html2text.HTML2Text()\n",
    "    h.ignore_links = True\n",
    "    h.ignore_images = True\n",
    "    return h.handle(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82ce00-9ddd-4d8c-92fe-f54662b6aab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(fetch_url(\"https://sports.yahoo.com/golf/live/2025-masters-second-round-live-leaderboard-and-updates-justin-rose-leads-scottie-scheffler-rory-mcilroy-at-augusta-national-110049747.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9b847-a4f7-4dac-ae3c-4b7fbf83db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    role=\"searcher\",\n",
    "    goal=\"Get information for the user\",\n",
    "    backstory=\"\",\n",
    "    tools=[tool(search_web), tool(fetch_url)]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2295b-3473-423c-bc14-e1b406e3fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task(\n",
    "    description=\"{query}\",\n",
    "    expected_output=\"Answers for {query}\",\n",
    "    agent=agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7ff0f-f121-4e35-8a90-7dc8ce886dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ced46-b7db-4c04-9cfb-0eb633c6b628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = crew.kickoff(inputs={\"query\": \"Who is speaking at PyTexas 2025?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b030dbb-45fe-4e8b-863e-dfd22da5e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ae67c-a8f0-4c25-b8af-5f2dc2d5a816",
   "metadata": {},
   "source": [
    "### Multi-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9595f-8cbc-4e23-ae8c-510b06a6637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "promoter_agent = Agent(\n",
    "    role=\"python_promoter\",\n",
    "    goal=\"Promote the use of Python\",\n",
    "    backstory=\"You love to use Python\",\n",
    "    tools=[tool(search_web), tool(fetch_url)]    \n",
    ")\n",
    "\n",
    "critic_agent = Agent(\n",
    "    role=\"python_critic\",\n",
    "    goal=\"Critique the use of Python\",\n",
    "    backstory=\"You hate Python and don't think it should ever be used\",\n",
    "    tools=[tool(search_web), tool(fetch_url)]    \n",
    ")\n",
    "\n",
    "summarizer_agent = Agent(\n",
    "    role=\"summarizer\",\n",
    "    goal=\"Summarize both sides of an argument\",\n",
    "    backstory=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae11fa-3573-448d-919f-98adaaadea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "promote_task = Task(\n",
    "    description=\"Promote Python\",\n",
    "    expected_output=\"Answers for why Python is a good choice for the question {query}\",\n",
    "    agent=promoter_agent,\n",
    ")\n",
    "\n",
    "critique_task = Task(\n",
    "    description=\"Critique Python\",\n",
    "    expected_output=\"Answers for why Python is a bad choice for the question {query}\",\n",
    "    agent=critic_agent,\n",
    ")\n",
    "\n",
    "summarize_task = Task(\n",
    "    description=\"Summarize pros and cons\",\n",
    "    expected_output=\"A balanced answer to the question {query}\",\n",
    "    context=[promote_task, critique_task],\n",
    "    agent=summarizer_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656a566-c0e9-4121-8156-4fa054f52806",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[promoter_agent, critic_agent],\n",
    "    tasks=[promote_task, critique_task, summarize_task],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea17ce-e600-4cb9-ad99-b8b36aa59109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = crew.kickoff(inputs={\"query\": \"Should I use Python to build my web app\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b640ef6-4e8c-4d9f-b2ca-f2bab42cc830",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3b0d35-b70a-4564-993b-ac503c67fb05",
   "metadata": {},
   "source": [
    "## Evaluation (A Brief Intro!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0c22c-db4a-496d-90b8-6fdb4c4b85fc",
   "metadata": {},
   "source": [
    "Since tool use is the model picking options from a finite list (the tools you give it), one way to evaluate tool use is to treat it as a multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376be9e4-09ef-434f-b7d6-c156304840f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_healthcare_benefits_documents(query: str) -> str:\n",
    "    pass\n",
    "\n",
    "def escalate_to_human() -> str:\n",
    "    pass\n",
    "\n",
    "def reschedule_appointment(new_time: str) -> str:\n",
    "    pass\n",
    "\n",
    "healthcare_functions = [search_healthcare_benefits_documents, escalate_to_human, reschedule_appointment]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbdc2d-1478-4d5a-9292-3e57ceb7496c",
   "metadata": {},
   "source": [
    "You are in control of when to stop the execution, so you don't have to run the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed76e4-9439-425e-a701-36cc5812e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_with_tool_calling(message, functions, message_history=None):\n",
    "    if message_history is None:\n",
    "        message_history = []\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=message_history + messages,\n",
    "        tools=[function_to_tool_spec(fn) for fn in functions]\n",
    "    )\n",
    "\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    # We stop without running any tool calls\n",
    "    if not tool_calls:\n",
    "        return None\n",
    "\n",
    "    return tool_calls[0].function.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb65a73-60cb-4058-a1b2-b2b3da8aac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_llm_with_tool_calling(\"What is my copay for primary care?\", functions=healthcare_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8d474-146d-4b3c-84c2-b63fcb530bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data = [\n",
    "    (\"What is my copay for primary care?\", 'search_healthcare_benefits_documents'),\n",
    "    (\"Talk to a human\", 'escalate_to_human'),\n",
    "    (\"Hi!\", None),\n",
    "    (\"Change my next appointment to Thursday\", \"reschedule_appointment\"),\n",
    "    (\"Are x rays covered?\", 'search_healthcare_benefits_documents'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4c0cd-8cc6-4e2e-9bb6-fc8f7848b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for message, expected_fn_name in evaluation_data:\n",
    "    actual_fn_name = call_llm_with_tool_calling(message, functions=healthcare_functions)\n",
    "    results.append(expected_fn_name == actual_fn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850751bf-1758-447f-972f-387581a52e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sum(results) / len(results)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74dfdd-04b7-4bae-80b3-4b54e7b23fee",
   "metadata": {},
   "source": [
    "More complicated evaluation topics:\n",
    "- Nondeterminism\n",
    "- How to handle the parameters?\n",
    "- How to handle multi-turn conversations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
